{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d623e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.31.0\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "                                              0.0/7.4 MB ? eta -:--:--\n",
      "     --                                       0.5/7.4 MB 16.6 MB/s eta 0:00:01\n",
      "     ------                                   1.3/7.4 MB 16.0 MB/s eta 0:00:01\n",
      "     -----------                              2.2/7.4 MB 17.4 MB/s eta 0:00:01\n",
      "     ------------------                       3.4/7.4 MB 19.7 MB/s eta 0:00:01\n",
      "     --------------------------               4.9/7.4 MB 22.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.4/7.4 MB 24.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.4/7.4 MB 24.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 22.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "                                              0.0/268.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 268.8/268.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (2.29.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "                                              0.0/3.5 MB ? eta -:--:--\n",
      "     ------------------                       1.6/3.5 MB 52.2 MB/s eta 0:00:01\n",
      "     -------------------------------          2.8/3.5 MB 35.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.5/3.5 MB 31.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 24.7 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.31.0)\n",
      "  Downloading safetensors-0.3.1-cp311-cp311-win_amd64.whl (263 kB)\n",
      "                                              0.0/263.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 263.7/263.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from transformers==4.31.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3_5\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3_5\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from requests->transformers==4.31.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from requests->transformers==4.31.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from requests->transformers==4.31.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3_5\\lib\\site-packages (from requests->transformers==4.31.0) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\hotaha\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\hotaha\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers\n",
    "#https://platform.openai.com/account/api-keys\n",
    "\n",
    "#https://github.com/onlyphantom/llm-python/blob/main/02_llama.py\n",
    "!pip install transformers==4.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7cc6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db67e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Value_Float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-02 13:33:06.333385</td>\n",
       "      <td>297.12</td>\n",
       "      <td>acXChar/mqtt</td>\n",
       "      <td>297.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-02 13:33:06.355900</td>\n",
       "      <td>306.14</td>\n",
       "      <td>acYChar/mqtt</td>\n",
       "      <td>306.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-02 13:33:06.364019</td>\n",
       "      <td>69.59</td>\n",
       "      <td>acZChar/mqtt</td>\n",
       "      <td>69.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-02 13:33:06.372301</td>\n",
       "      <td>0.25</td>\n",
       "      <td>currentSenChar/mqtt</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-02 13:33:06.372301</td>\n",
       "      <td>296.30</td>\n",
       "      <td>acXChar/mqtt</td>\n",
       "      <td>296.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime   Value                Topic  Value_Float\n",
       "0  2023-08-02 13:33:06.333385  297.12         acXChar/mqtt       297.12\n",
       "1  2023-08-02 13:33:06.355900  306.14         acYChar/mqtt       306.14\n",
       "2  2023-08-02 13:33:06.364019   69.59         acZChar/mqtt        69.59\n",
       "3  2023-08-02 13:33:06.372301    0.25  currentSenChar/mqtt         0.25\n",
       "4  2023-08-02 13:33:06.372301  296.30         acXChar/mqtt       296.30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = \"C:/Users/hotaha/OneDrive - dormakaba Group/Desktop/Python/LOF dbscan anomaly detection clustering/data_export_ED_020823_normal.csv\"\n",
    "\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "data = pd.read_csv(filepath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b5666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"Calculate the the rows of the dataset:\\n\"\n",
    "#prompt_2 = \"Analyze the data to find interesting patterns or insights:\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6977d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to Prompt 1:\n",
      "Calculate the the rows of the dataset:\n",
      "\n",
      "$ curl -X POST -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -H 'Content-Type: application/json' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\":\"json\"}' -d '{\"data\":\"{$_.data}', \"data_type\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=1024, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Generate responses for the two prompts\n",
    "response_1 = generate_response(prompt_1)\n",
    "#response_2 = generate_response(prompt_2)\n",
    "\n",
    "print(\"Response to Prompt 1:\")\n",
    "print(response_1)\n",
    "\n",
    "#print(\"Response to Prompt 2:\")\n",
    "#print(response_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801c4586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      "count rows of the file.\n",
      "\n",
      "The following example shows how to create a new file with the following code:\n",
      "\n",
      "import { File } from './file'; import { File } from './file.js'; import { File } from './file.js/js'; import { File } from './file.js/js/js.js'; import { File } from './file.js/js/js.js/js.js '\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "prompt = \"count rows of the file\"\n",
    "\n",
    "def generate_response(prompt, max_length=100):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Generate response using GPT-2\n",
    "generated_response = generate_response(prompt)\n",
    "print(\"Generated Response:\")\n",
    "print(generated_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ecdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8bee71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPT3Tokenizer' from 'transformers' (C:\\Users\\hotaha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT3Tokenizer, GPT3ForCausalLM\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m GPT3Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-2.7B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT3ForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-2.7B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GPT3Tokenizer' from 'transformers' (C:\\Users\\hotaha\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import GPT3Tokenizer, GPT3ForCausalLM\n",
    "\n",
    "tokenizer = GPT3Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "model = GPT3ForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=1024, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Generate responses for the two prompts\n",
    "response_1 = generate_response(prompt_1)\n",
    "\n",
    "\n",
    "print(\"Response to Prompt 1:\")\n",
    "print(response_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7def031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
